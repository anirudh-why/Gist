"""Generation layer (Step 5).

Utilities to construct prompts from retrieved context and call a local LLM
(Llama 2 7B/13B via llama.cpp) to produce clear, student-friendly explanations.
"""
